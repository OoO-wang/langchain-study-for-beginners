{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T09:14:40.362341Z",
     "start_time": "2025-10-17T09:14:39.539319Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=os.getenv(\"MODEL_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=os.getenv(\"MODEL_NAME\", \"gpt-3.5-turbo\"),\n",
    "    temperature=0\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T09:17:36.704874Z",
     "start_time": "2025-10-17T09:17:32.964426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents.middleware import before_model, after_model, wrap_model_call\n",
    "from langchain.agents.middleware import AgentState, ModelRequest\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "# Node-style: logging before model calls\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "    return None\n",
    "\n",
    "# Node-style: validation after model calls\n",
    "@after_model(can_jump_to=[\"end\"])\n",
    "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(\"validate_output last_message!\")\n",
    "    if \"BLOCKED\" in last_message.content:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Use decorators in agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[log_before_model, validate_output],\n",
    ")\n",
    "\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"Hello!, What is your name?\")]})\n",
    "\n",
    "print(response)"
   ],
   "id": "48db199d2d9a3c60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call model with 1 messages\n",
      "validate_output last_message!\n",
      "{'messages': [HumanMessage(content='Hello!, What is your name?', additional_kwargs={}, response_metadata={}, id='7cd213b2-5452-4f20-82bc-71387d64efe2'), AIMessage(content=\"Hello! I'm Doubao. It's great to meet you! üòä\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 91, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 66, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'doubao-seed-1-6-250615', 'system_fingerprint': '', 'id': '021760692654039d0e7756e6488d797bcebaadd1d47697938c2d9', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--eeebac0f-9cb1-4c46-9981-83c5528bee6e-0', usage_metadata={'input_tokens': 91, 'output_tokens': 82, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 66}})]}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal, Callable\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def github_create_issue(repo: str, title: str) -> dict:\n",
    "    \"\"\"Create an issue in a GitHub repository.\"\"\"\n",
    "    return {\"url\": f\"https://github.com/{repo}/issues/1\", \"title\": title}\n",
    "\n",
    "@tool\n",
    "def gitlab_create_issue(project: str, title: str) -> dict:\n",
    "    \"\"\"Create an issue in a GitLab project.\"\"\"\n",
    "    return {\"url\": f\"https://gitlab.com/{project}/-/issues/1\", \"title\": title}\n",
    "\n",
    "all_tools = [github_create_issue, gitlab_create_issue]\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    provider: Literal[\"github\", \"gitlab\"]\n",
    "\n",
    "class ToolSelectorMiddleware(AgentMiddleware):\n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"Select tools based on the VCS provider.\"\"\"\n",
    "        provider = request.runtime.context.provider\n",
    "\n",
    "        if provider == \"gitlab\":\n",
    "            selected_tools = [t for t in request.tools if t.name == \"gitlab_create_issue\"]\n",
    "        else:\n",
    "            selected_tools = [t for t in request.tools if t.name == \"github_create_issue\"]\n",
    "\n",
    "        request.tools = selected_tools\n",
    "        return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=all_tools,\n",
    "    middleware=[ToolSelectorMiddleware()],\n",
    "    context_schema=Context,\n",
    ")\n",
    "\n",
    "# Invoke with GitHub context\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Open an issue titled 'Bug: where are the cats' in the repository `its-a-cats-game`\"}]\n",
    "    },\n",
    "    context=Context(provider=\"github\"),\n",
    ")\n",
    "\n",
    "## langchain‰ª£Á†Åbug‰∫ÜÔºåModelResponse‰∏çËÉΩÂØºÂÖ•"
   ],
   "id": "66e0f74c9fa047a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
